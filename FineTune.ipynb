{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from src.model import D_GAT\n",
    "from src.mol_processing import Read_mol_data, Generate_dataloader\n",
    "from src.train_eval import Train_eval, Test_NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to define \n",
    "1. The datset to finetune: dataset\n",
    "2. The task name in file: task_name\n",
    "3. The type of tasks: target_type ('classification', 'regression')\n",
    "4. The metrics to evaluate: metrics ('AUC', 'RMSE', 'MAE')\n",
    "5. The name of stored model: store_name (dataset + '.pth' or None)\n",
    "\n",
    "However, if you test the datasets used in our paper (Tox21 SIDER MUV HIV BBBP BACE ClinTox ToxCast PCBA ESOL FreeSolv Lipo QM7 QM8 QM9), you only need to define the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = 'FreeSolv' # Tox21 SIDER MUV HIV BBBP BACE ClinTox ToxCast PCBA ESOL FreeSolv Lipo QM7 QM8 QM9\n",
    "config_file_path = './config/config.json'\n",
    "\n",
    "if dataset in ['HIV', 'BBBP', 'Tox21', 'SIDER', 'MUV', 'BACE', 'ClinTox', 'ToxCast', 'PCBA']:\n",
    "    target_type = 'classification'\n",
    "    metrics = 'AUC'\n",
    "    task_name = None\n",
    "elif dataset in ['ESOl', 'Lipo', 'FreeSolv']:\n",
    "    target_type = 'regression'\n",
    "    metrics = 'RMSE'\n",
    "    task_name = None\n",
    "elif dataset in [ 'QM7', 'QM8', 'QM9']:\n",
    "    target_type = 'regression'\n",
    "    metrics = 'MAE'\n",
    "    task_name = None\n",
    "else:\n",
    "    print('Please define the target type, task_name and metrics!')\n",
    "#     target_type = 'classification'\n",
    "#     metrics = 'AUC'\n",
    "#     target_type = 'regression'\n",
    "#     metrics = 'RMSE'\n",
    "#     metrics = 'MAE'\n",
    "#     task_name = ['u0_atom'] #for QM7\n",
    "\n",
    "store_name = dataset + '.pth'\n",
    "# store_name = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is to load and process data, and load pre-training model. Nothing to define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read and process the collected data...\n",
      "----------------------------------------\n",
      "Dataset:  FreeSolv\n",
      "Example: \n",
      "iupac     methanesulfonyl chloride\n",
      "smiles                CS(=O)(=O)Cl\n",
      "expt                         -4.87\n",
      "calc                        -6.219\n",
      "Name: 0, dtype: object\n",
      "Number of molecules: 642\n",
      "1 / 1  finished!\n",
      "Training dataset finished\n",
      "Val dataset finished\n",
      "Test dataset finished\n",
      "Load PreTraining mdoel:  ./model/PreTraining.pth\n",
      "Model prepared!\n"
     ]
    }
   ],
   "source": [
    "assert target_type in ['classification', 'regression']\n",
    "if target_type == 'classification':\n",
    "    assert metrics in ['AUC']\n",
    "elif target_type == 'regression':\n",
    "    assert metrics in ['RMSE', 'MAE']\n",
    "    \n",
    "mol_train, mol_val, mol_test, mean, std = Read_mol_data(dataset, task_name, target_type)\n",
    "train_dataloader, val_dataloader,test_dataloader = Generate_dataloader(dataset, mol_train, mol_val, mol_test)\n",
    "model, best_score = D_GAT(dataset, mol_train, config_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you load the fine-tuned model, next section could be used to evaluate its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Following code is to evaluate the fine-tuning model\n",
    "# Loss, auc = Test_NN(dataset, model, test_dataloader, metrics, target_type, mean, std)\n",
    "# print('Mean Loss: ', Loss)\n",
    "# if target_type == 'classification':\n",
    "#     print('Mean AUC: ', auc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are going to fine-tune your model. It may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For first training part:\n",
      "New best model saved!\n",
      "|  1/20 epochs | lr 1.0e-04 |  1 s | Train 3.45316 | Val 6.18611 | Test 4.52748\n",
      "New best model saved!\n",
      "|  2/20 epochs | lr 9.9e-05 |  1 s | Train 2.60138 | Val 4.88129 | Test 3.30626\n",
      "New best model saved!\n",
      "|  3/20 epochs | lr 9.9e-05 |  1 s | Train 2.16218 | Val 4.37161 | Test 3.07191\n",
      "New best model saved!\n",
      "|  4/20 epochs | lr 9.9e-05 |  1 s | Train 1.93665 | Val 3.90612 | Test 2.75351\n",
      "New best model saved!\n",
      "|  5/20 epochs | lr 9.8e-05 |  1 s | Train 1.80044 | Val 3.72002 | Test 2.67885\n",
      "New best model saved!\n",
      "|  6/20 epochs | lr 9.8e-05 |  2 s | Train 1.71770 | Val 3.44444 | Test 2.42028\n",
      "New best model saved!\n",
      "|  7/20 epochs | lr 9.8e-05 |  1 s | Train 1.68629 | Val 3.44088 | Test 2.43212\n",
      "New best model saved!\n",
      "|  8/20 epochs | lr 9.7e-05 |  1 s | Train 1.65436 | Val 3.28742 | Test 2.28490\n",
      "New best model saved!\n",
      "|  9/20 epochs | lr 9.7e-05 |  1 s | Train 1.61782 | Val 3.24079 | Test 2.28508\n",
      "New best model saved!\n",
      "| 10/20 epochs | lr 9.7e-05 |  1 s | Train 1.59048 | Val 3.22625 | Test 2.28585\n",
      "New best model saved!\n",
      "| 11/20 epochs | lr 9.6e-05 |  1 s | Train 1.53875 | Val 3.10024 | Test 2.14883\n",
      "| 12/20 epochs | lr 9.6e-05 |  1 s | Train 1.51218 | Val 3.11547 | Test 2.19416\n",
      "New best model saved!\n",
      "| 13/20 epochs | lr 9.6e-05 |  1 s | Train 1.52932 | Val 3.00630 | Test 2.14487\n",
      "New best model saved!\n",
      "| 14/20 epochs | lr 9.5e-05 |  1 s | Train 1.45853 | Val 2.96785 | Test 2.10736\n",
      "New best model saved!\n",
      "| 15/20 epochs | lr 9.5e-05 |  1 s | Train 1.40847 | Val 2.94514 | Test 2.09507\n",
      "New best model saved!\n",
      "| 16/20 epochs | lr 9.5e-05 |  1 s | Train 1.44916 | Val 2.91435 | Test 2.09537\n",
      "New best model saved!\n",
      "| 17/20 epochs | lr 9.4e-05 |  1 s | Train 1.44267 | Val 2.82142 | Test 2.01344\n",
      "New best model saved!\n",
      "| 18/20 epochs | lr 9.4e-05 |  1 s | Train 1.38464 | Val 2.81615 | Test 2.00922\n",
      "| 19/20 epochs | lr 9.4e-05 |  1 s | Train 1.44895 | Val 2.85006 | Test 2.03919\n",
      "New best model saved!\n",
      "| 20/20 epochs | lr 9.3e-05 |  1 s | Train 1.43382 | Val 2.78707 | Test 1.99844\n",
      "The Training is finished: 1.434e+00 2.787e+00 1.998e+00 0.00000 0.00000\n",
      "1st training is finished:\n",
      "Train loss: 1.434e+00 | Val loss: 2.787e+00 | Test loss: 1.998e+00\n",
      "\n",
      "For second training part:\n",
      "New best model saved!\n",
      "|  1/30 epochs | lr 1.0e-04 |  2 s | Train 1.39192 | Val 2.00689 | Test 1.71697\n",
      "|  2/30 epochs | lr 9.9e-05 |  1 s | Train 1.40378 | Val 2.02567 | Test 1.94937\n",
      "New best model saved!\n",
      "|  3/30 epochs | lr 9.9e-05 |  1 s | Train 1.16932 | Val 1.82757 | Test 1.76162\n",
      "New best model saved!\n",
      "|  4/30 epochs | lr 9.9e-05 |  1 s | Train 1.01429 | Val 1.61230 | Test 1.67847\n",
      "New best model saved!\n",
      "|  5/30 epochs | lr 9.8e-05 |  1 s | Train 0.98928 | Val 1.54965 | Test 1.62604\n",
      "|  6/30 epochs | lr 9.8e-05 |  1 s | Train 0.99311 | Val 1.70157 | Test 1.84062\n",
      "|  7/30 epochs | lr 9.8e-05 |  1 s | Train 1.07453 | Val 1.56265 | Test 1.62339\n",
      "|  8/30 epochs | lr 9.7e-05 |  1 s | Train 1.28458 | Val 1.64583 | Test 1.69516\n",
      "|  9/30 epochs | lr 9.7e-05 |  1 s | Train 1.07530 | Val 1.59378 | Test 1.60383\n",
      "| 10/30 epochs | lr 9.7e-05 |  1 s | Train 0.99171 | Val 1.68741 | Test 1.67804\n",
      "New best model saved!\n",
      "| 11/30 epochs | lr 9.6e-05 |  1 s | Train 1.00784 | Val 1.51337 | Test 1.58972\n",
      "| 12/30 epochs | lr 9.6e-05 |  1 s | Train 0.86379 | Val 1.53077 | Test 1.61506\n",
      "| 13/30 epochs | lr 9.6e-05 |  1 s | Train 0.84605 | Val 1.57769 | Test 1.63527\n",
      "| 14/30 epochs | lr 9.5e-05 |  1 s | Train 0.82314 | Val 1.72529 | Test 1.62156\n",
      "| 15/30 epochs | lr 9.5e-05 |  1 s | Train 0.82600 | Val 1.68024 | Test 1.63039\n",
      "| 16/30 epochs | lr 9.5e-05 |  1 s | Train 0.78076 | Val 1.65539 | Test 1.66143\n",
      "| 17/30 epochs | lr 9.4e-05 |  1 s | Train 0.86970 | Val 1.66775 | Test 1.67904\n",
      "| 18/30 epochs | lr 9.4e-05 |  1 s | Train 0.92345 | Val 1.68796 | Test 1.60761\n",
      "| 19/30 epochs | lr 9.4e-05 |  1 s | Train 0.98257 | Val 1.80296 | Test 1.69097\n",
      "| 20/30 epochs | lr 9.3e-05 |  1 s | Train 0.82393 | Val 1.76576 | Test 1.60482\n",
      "| 21/30 epochs | lr 9.3e-05 |  1 s | Train 0.77423 | Val 1.67399 | Test 1.69494\n",
      "| 22/30 epochs | lr 9.3e-05 |  1 s | Train 0.85867 | Val 1.73261 | Test 1.55038\n",
      "| 23/30 epochs | lr 9.2e-05 |  1 s | Train 0.76505 | Val 1.77951 | Test 1.65821\n",
      "| 24/30 epochs | lr 9.2e-05 |  1 s | Train 0.74612 | Val 1.73504 | Test 1.69066\n",
      "| 25/30 epochs | lr 9.2e-05 |  1 s | Train 0.70916 | Val 1.75943 | Test 1.65733\n",
      "| 26/30 epochs | lr 9.2e-05 |  1 s | Train 0.74786 | Val 1.76882 | Test 1.62518\n",
      "| 27/30 epochs | lr 9.1e-05 |  1 s | Train 0.70378 | Val 1.76465 | Test 1.66720\n",
      "| 28/30 epochs | lr 9.1e-05 |  1 s | Train 0.69933 | Val 1.64578 | Test 1.67385\n",
      "| 29/30 epochs | lr 9.1e-05 |  1 s | Train 0.74858 | Val 1.57072 | Test 1.63207\n",
      "| 30/30 epochs | lr 9.0e-05 |  1 s | Train 0.77920 | Val 1.77837 | Test 1.62185\n",
      "The Training is finished: 1.008e+00 1.513e+00 1.590e+00 0.00000 0.00000\n",
      "2nd training is finished:\n",
      "Train loss: 1.008e+00 | Val loss: 1.513e+00 | Test loss: 1.590e+00\n",
      "\n",
      "Training stage is finished and final results are shown below:\n",
      "Train loss: 1.008e+00 | Val loss: 1.513e+00 | Test loss: 1.590e+00\n"
     ]
    }
   ],
   "source": [
    "# To fine-tune the model\n",
    "model, best_score = Train_eval(dataset, model, train_dataloader, val_dataloader,test_dataloader, best_score, config_file_path, store_name, metrics, target_type, mean, std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
